\chapter{ANN Classifier for Top Quark Reconstruction}
\label{ch:classifier}
The study of single top quark $s$-channel production is important in exploring the electroweak sector of the SM, which predicts three production channels (refer to Section \ref{sec:theory_top}). Deviations from the SM prediction of its cross section may hint to mechanisms beyond the standard model (BSM) \cite{CMS16}. These single top quarks account for a small proportion of the total production of single top quarks. Therefore, a good separation between signal and background events is required, with single top quarks produced via the $s$-channel constituting signal and those produced via other production modes background events. The improvement of the reconstruction for $s$-channel single top quarks increases the separation between signal and background events.

This chapter describes the development of an artificial neural network classifier for the reconstruction of the top quark.
Section \ref{sec:ch-5-simulation} describes the generation of simulation events, which will be used to train the classifier. Section \ref{sec:ch-5-preselection} outlines the preselection of events for increasing the signal-to-background ratio. Section \ref{sec:ch-5-best-mass} introduces the method currently in use for top quark reconstruction, the best-mass method, which this work aims to improve upon. After laying out the input variables of the network in section \ref{sec:ch-5-input-vars}, sections \ref{sec:ch-5-network} and \ref{sec:ch-5-training} describe the configuration and training of the ANN followed by an evaluation of the performance of the classifier and comparison with the best-mass method in section \ref{sec:ch-5-eval}.

\section{Simulation of Events and Corrections}
\label{sec:ch-5-simulation}
Simulation of processes is done at year 2017 conditions at the CMS. The $s$-channel single top quark production process is simulated with the \emph{MAD-GRAPH5\_AMC@NLO MC} event generator, version 2.2.2, using the 4FS description \cite{Fal18} and every simulation involving top quarks uses their literature mass of \SI{172.5}{GeV}. The parton shower and hadronization process are performed using Pythia version 8.2. The probability for each parton in the initial state to be present in the proton with a given fraction of the proton momentum is obtained by the \emph{NNPDF31\_NNLO\_HESSIAN\_PDFAS PDF} \cite{Fal18}.

Several corrections are applied to the simulations to consider differences between simulation and detector data. The number of pileup interactions is reweighted based on the distribution obtained from minimum-bias events in order to resemble the actual conditions. During reconstruction and selection of leptons dedicated scale factors are applied to simulated events to account for differences in the kinematic properties of the lepton between simulation and data. Finally, the efficiency of the employed b tagging algorithm is corrected to resemble the same number of events in simulation with a certain number of b-tagged jets as in data \cite{Fal18}.

\section{Preselection}
\label{sec:ch-5-preselection}
The purpose of preselection is to achieve an optimal signal-to-background ratio. As shown in Figure \ref{fig:ch_4_single_top_reco}, the observed final state products are characterized by the presence of one isolated muon or electron, two \Pbottom quarks, one originating from the top quark decay and one recoiling against the top quark, and a neutrino resulting in a missing transverse energy (MET).

Events with either one muon or electron are selected, with the selection criteria for the muon being $p_T > \SI{30}{GeV}$, isolation of at most 0.06 and for the electron $p_T > \SI{35}{GeV}$ with a maximum pseudorapidity $\eta$ of 2.1.

The leptons (muon or electron) are required to originate from the primary vertex (PV), which is reconstructed using the particle-flow (PF) algorithm from at least four tracks and required to be located within a cylinder of radius of \SI{2}{cm} and length of \SI{24}{cm} around the center of detector. 

They must satisfy certain quality criteria (tight ID), as described in detail in \cite{Fal18}. Events with more than one lepton are rejected if at least one of the additional leptons passes the loose ID requirement of the corresponding lepton flavor, which significantly reduces the contribution from background processes.

Jets with a transverse momentum $p_T$ of \SI{40}{GeV}, passing the PF jet ID requirement described in \cite{Fal18}, and a distance of $\Delta R \geq 0.4$ from the $\eta-\phi$ plane to the selected lepton are considered for the analysis. Additionally, jets considered for \Pbottom tagging must have an absolute pseudorapidity $\eta \leq 2.4$, otherwise $\eta \leq 4.7$ is allowed.

As the final state of the $s$-channel single top quark production has two jets, the signal region of the analysis is the 2-jets-2-tags (2j2t) region.

\section{Reconstruction with the Best-Mass Method}
\label{sec:ch-5-best-mass}
\begin{figure}[h]
    \centering
    \input{assets/chap04/top_s_reco_1}
    \caption{s-channel single top quark production with the top quark decaying in a \PWplus boson and a \Pbottom quark. The \PWplus quark decays either in a positron and electron neutrino or a muon and muon neutrino.}
    \label{fig:ch_4_single_top_reco}
\end{figure}
The top quark can be easily reconstructed from its decay products, the b jet, the lepton and the neutrino (see Figure \ref{fig:ch_4_single_top_reco}), by adding their four-momenta together. Since events stem from the 2-jets-2-tags signal region, the assignment of a \Pbottom-tagged jet to the b jet from the top quark is ambiguous because of the two b-tagged jets in each event. The b-tagged jet that results in a reconstructed top mass closer to the literature value of \SI{172.5}{GeV} (best-mass method) is selected for the reconstruction \cite{Fal18}.

\section{Input Variables}
\label{sec:ch-5-input-vars}
The task of the classifier will be to accurately differentiate which of the two \Pbottom jets in the final products in Figure \ref{fig:ch_4_single_top_reco} originates from the hadronization of the top quark.

This section lists the choice of input variables for which the classifier had the highest discriminatory power. Various kinematic, angular and jet variable combinations were tried out, with those listed in Table \ref{tab:ch_4_input_vars} yielding the most significant improvement in top quark reconstruction. More details can be found in Section \ref{sec:ch-5-training}.

\emph{Kinematic variables} describe the state of motion of an object, i.e. momentum, direction, or the distance $\Delta R=\sqrt{\Delta \eta^2 + \Delta \phi^2}$ between two objects. They provide good discrimination, because one of the jets recoils against the top quark. \emph{Angular variables} contain angular information for reconstructed objects, whereas \emph{jet variables} of the momenta and count of detected jets.

\begin{table}[h]
    \caption{The 12 variables that were used for the classifier.}
    \label{tab:ch_4_input_vars}
    \begin{center}
        \begin{tabular}{ll}
            \hline
            Variable & Description\\
            \hline
            $p_T(j_1)$ & Transverse momentum of first jet\\
            $\eta(j_1)$ & Pseudorapidity of first jet\\
            $\phi(j_1)$ & $\phi$ of first jet\\
            $m_0(j_1)$ & Invariant mass of first jet\\

            $p_T(j_2)$ & Transverse momentum of second jet\\
            $\eta(j_2)$ & Pseudorapidity of second jet\\
            $\phi(j_2)$ & $\phi$ of second jet\\
            $m_0(j_2)$ & Invariant mass of second jet\\

            $\Delta R(j_1, w)$ & Distance between the first jet and the \PWplus boson\\
            $\Delta R(j_1, lep)$ & Distance between the first jet and the lepton\\
            $\Delta R(j_2, w)$ & Distance between the second jet and the \PWplus boson\\
            $\Delta R(j_2, lep)$ & Distance between the second jet and the lepton\\
            \hline
        \end{tabular}
    \end{center}
\end{table}

Preselected simulation data, as described in Sections \ref{sec:ch-5-simulation} and \ref{sec:ch-5-preselection}, were made available in the form of \emph{ROOT} files. The values of the variables listed previously were either derived by applying algorithms to or provided directly as measurements from this data. 

Next, the values were standardized using \emph{scikit-learn}'s preprocessing module for them to look standard normally distributed by removing the mean value for each feature, then scaling by dividing non-constant features by their standard deviation \cite{scikit-learn}. This standardization of values speeds up the convergence of the DNN.

Finally, labeling of the values was performed. After training the DNN, the resulting model can be applied to unlabeled data and an accurate label can be predicted for that data. The information which of the two jets resulted by the hadronization of the top quark is available in simulation data and was used in labeling. For every simulation sample, two sets of data were generated, with each jet being assigned $j_1$ and $j_2$ interchangeably: the data was labeled with $1$ if jet $j_1$ resulted from the top quark, otherwise with $0$.

\section{Network Topology}
\label{sec:ch-5-network}

The performance of the classifier depends to a smaller degree by the topology, the hyperparameter settings of the DNN and the used regularization methods.

A feed-forward fully-connected neural network with 12 neurons in the input layer, four hidden layers containing 100 neurons each, and an output layer consisting of a single neuron, was used. The ReLU function was selected for the activation of neurons in the hidden layers and the sigmoid function for the activation of the neuron in the output layer. Cross-entropy was chosen as the loss function, since a faster DNN convergence even for poorly selected initialization weights has been observed. The Adam optimizer with an initial learning rate of 0.0001 was used by default for loss function minimization, due to its established reliability among other optimizers in similar classification problems. Some tests with the stochastic gradient descent (SGD) optimizer for the same input variables seemed to validate this assumption.

\begin{table}[h]
    \caption{Overview of DNN hyperparameter settings for the ANN classifier}
    \label{tab:ch_4_ann_topology}
    \begin{center}
        \begin{tabular}{lc}
            \hline
            Hyperparameter & Value\\
            \hline
            Input Layer Neurons & 12\\
            Hidden Layers & 4\\
            Hidden Layer Neurons & 100\\
            Hidden Layer Activation Function & ReLU\\
            Output Layer Neurons & 1\\
            Output Layer Activation Function & Sigmoid\\
            Optimizer & ADAM\\
            Initial Learning Rate & 0.0001\\
            Dropout Rate & 0.25\\
            Early Stopping Patience & 5\\
            Reduce-On-Plateau Factor & 0.5\\
            Reduce-On-Plateau Patience & 2\\
            \hline
        \end{tabular}
    \end{center}
\end{table}

To prevent overfitting, the dropout and early stopping methods introduced in Section \ref{sec:ch_3_regularization} were used. Batch normalization was briefly tested in conjunction with dropout, which resulted in a poorer performance of the classifier, these tests were however far from exhaustive. The developed classifier uses a dropout rate of 0.25 and an early stopping patience of five consecutive epochs without any improvement of the loss on validation data.

Furthermore, the reduce-on-plateau method with a factor of 0.5 and a patience of two epochs without improvement of the loss on validation data was applied: the learning rate is reduced by a factor of two if the validation loss does not decrease for two successive epochs. This dynamic adaptation of the learning rate increases the likelihood of finding an accurate minimum for the loss function within a single training instance, avoiding the need for manual fine-tuning of the learning rate and the repetition of the training process after every change.

A summary of hyperparameter values that were used to build the DNN can be found in Table \ref{tab:ch_4_ann_topology}.

The neuron in the output layer returns values between 0 and 1 to discriminate between the two classes 0 and 1, which stand for jet $j_2$ and $j_1$ (Table \ref{tab:ch_4_input_vars}) originating from the top quark respectively. To find which of the two jets for an unlabeled set of data is a product of the hadronization of the top quark, the data set has to be evaluated twice against the trained model, with the two jets being assigned $j_1$ and $j_2$ interchangeably, similar to the labeling procedure outlined in Section \ref{sec:ch-5-input-vars}. The evaluation of the data set that returns the highest output value implies that the jet assigned $j_1$ came from the top quark.

\section{Training}
\label{sec:ch-5-training}

\section{Evaluation}
\label{sec:ch-5-eval}